{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7e2183",
   "metadata": {},
   "source": [
    "# fast-tabulous homesite quote success app\n",
    "> This app loads a previously trained model and uses it to predict quote success rate using user input to change fields. User input uses ipywidgets generated on the fly to match allow altering of the most sensitive fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eca4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fastai.tabular.all import *\n",
    "from IPython.display import display\n",
    "from IPython.utils import io  # using io.capture_output\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdee60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On GPU instance run the following commands\n",
    "\n",
    "#     to = TabularPandas(df=df_train, procs=procs, cat_names=cat_names, cont_names=cont_names, y_names=y_names,splits=splits, y_block=y_block)dls = to.dataloaders(bs=bs, val_bs=val_bs, layers=layers, embed_ps=emb_dropout, ps=dropout)\n",
    "#     dls = to.dataloaders(bs=bs, val_bs=val_bs, layers=layers, embed_ps=emb_dropout, ps=dropout)\n",
    "#     learn = tabular_learner(dls, metrics=roc_auc_binary)\n",
    "    \n",
    "#     save_pickle(\"to_0708.pkl\", to)\n",
    "#     learn_model_cpu = learn.model.to('cpu')\n",
    "#     save_pickle(\"learn_model_cpu_0708.pkl\", learn_model_cpu)\n",
    "#     dls.to('cpu')\n",
    "#     save_pickle(\"dls_cpu_0708.pkl\", dls)\n",
    "\n",
    "\n",
    "# Now specify the folder which contains the original kaggle data (train.csv and test.csv) \n",
    "# and the trained TabularModel (learn_model_cpu_0708.pkl) and DataLoaders (dls_cpu_0708.pkl)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# path = Path('data/homesite-quote')\n",
    "logger = logging.getLogger(\"load_pickled_model\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "URL_MODEL = \"https://drive.google.com/file/d/1UBcTSyBwkGqjV4BymhUrJgORG9mqVDqU/view?usp=sharing\"\n",
    "URL_DLS = \"https://drive.google.com/file/d/173VCxcHV58rhExBNi8HfWqOKh_PELLu6/view?usp=sharing\"\n",
    "URL_TEST = \"https://drive.google.com/file/d/1-OuitILRZKJUMeB4mHpS_pV0_3ovFQnd/view?usp=sharing\"\n",
    "URL_TRAIN = \"https://drive.google.com/file/d/1-NtnEyuR7pbQb826D_kFiYGYR2kYO0c1/view?usp=sharing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcee33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(URL_MODEL, \"learn_model_cpu_0708.pkl\")\n",
    "learn_model_cpu = load_pickle(\"learn_model_cpu_0708.pkl\")\n",
    "urllib.request.urlretrieve(URL_DLS, \"dls_cpu_0708.pkl\")\n",
    "dls_cpu = load_pickle(\"dls_cpu_0708.pkl\")\n",
    "# to = load_pickle(path/\"to_0708.pkl\")  # optional for now. needed for xgboost\n",
    "learn=TabularLearner(dls=dls_cpu, model=learn_model_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f705c04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:load_pickled_model:Trained deep learning model has a roc_auc_score of 0.9630509311593953\n"
     ]
    }
   ],
   "source": [
    "preds, targs = learn.get_preds()\n",
    "logger.warning(f\"Trained deep learning model has a roc_auc_score of {roc_auc_score(to_np(targs), to_np(preds[:,1]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "962ed0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(URL_TRAIN, \"train.csv\")\n",
    "urllib.request.urlretrieve(URL_TEST, \"test.csv\")\n",
    "df_train = pd.read_csv('train.csv', low_memory=False, parse_dates=['Original_Quote_Date'], index_col=\"QuoteNumber\")\n",
    "df_test = pd.read_csv('test.csv', low_memory=False, parse_dates=['Original_Quote_Date'], index_col=\"QuoteNumber\")\n",
    "sr_conv = df_train['QuoteConversion_Flag']\n",
    "df_train.drop('QuoteConversion_Flag', inplace=True, axis=1)\n",
    "df = pd.concat([df_train, df_test])\n",
    "df = add_datepart(df, 'Original_Quote_Date')\n",
    "logger.debug(f\"{df.shape} {df_train.shape} {df_test.shape} {sr_conv.shape}\")\n",
    "df_train = None\n",
    "df_test = None\n",
    "qn_min = sr_conv.index.min()\n",
    "qn_max = sr_conv.index.max()\n",
    "qn = random.randint(qn_min, qn_max)  # pick an initial quote at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76d997bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst_ind_value(df, field):\n",
    "    \"\"\"Return the list of independent values to be tested for specified field\"\"\"\n",
    "    num_unique = df[field].nunique()\n",
    "    # If number of unique values is under 30 then try every value (or for objects try every value)\n",
    "    if num_unique < 30 or df.dtypes[field] == 'O':\n",
    "        return df[field].unique()\n",
    "    else:\n",
    "        if df.dtypes[field] == \"int64\":\n",
    "            vmin = df[field].min()\n",
    "            vmax = df[field].max()\n",
    "            return [vmin + (vmax - vmin) * i // 10 for i in range(11)]\n",
    "        elif df.dtypes[field] == \"float64\":\n",
    "            vmin = df[field].min()\n",
    "            vmax = df[field].max()\n",
    "            return [vmin + (vmax - vmin) * i / 10 for i in range(11)]\n",
    "        else:\n",
    "            logger.warning(f\"Unknown type {field} {num_unique} {df.dtypes[field]!r}\")\n",
    "            return []\n",
    "\n",
    "def tf_equal_or_nan(a, b):\n",
    "    \"\"\"same as normal equals except np.nan == np.nan which is not normally True\"\"\"\n",
    "    if a == b:\n",
    "        return True\n",
    "    try:\n",
    "        if np.isnan(a) and np.isnan(b):\n",
    "            return True\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def nan_if_nan(n):\n",
    "    \"\"\"Can't include np.nan in dropdowns as np.nan != np.nan. Instead use a str\"\"\"\n",
    "    try:\n",
    "        if np.isnan(n):\n",
    "            return \"nan\"\n",
    "    except TypeError as te:\n",
    "        pass\n",
    "    return n\n",
    "        \n",
    "def df_for_field(df_ind_original, f, lst_v):\n",
    "    \"\"\"predicts quote success after changing field f from v_original to each value in lst_v.\n",
    "    If prediction changes then quote is sensitive to the value of this field and True is returned\n",
    "    Keyword arguments\n",
    "        ind_original: all independent values from original quote (numpy Series with index = field names) \n",
    "        f: field name\n",
    "        lst_v: list of alternative values of independent value in field f\n",
    "    Returns\n",
    "        dataframe of alternative values in field f and all other fields staying the same and a column called fieldname\n",
    "    \"\"\"\n",
    "    # Create a DataFrame which has every row identical except for field in question\n",
    "    # Field f iterates through every value provided\n",
    "    ind_other = df_ind_original.drop(f, axis=1)  # fields other than f\n",
    "    ind_f = pd.DataFrame(data={f: lst_v, \"fieldname\": [f] * len(lst_v)}, index=[df_ind_original.index[0]] * len(lst_v))\n",
    "    # Merge these two DataFrames to create one with all rows identical except field f\n",
    "    return pd.merge(ind_other, ind_f, right_index=True, left_index=True)\n",
    "\n",
    "def sensitivity_analysis(ind_original):\n",
    "    \"\"\"Using data from Series of independent variables do a sensitivity analysis on all independent variables\"\"\"\n",
    "    time_start = datetime.now()\n",
    "    # Original prediction before changes\n",
    "    prd = learn.predict(ind_original)\n",
    "    logger.debug(f\"After one predict time = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    # Predicted quote conversion flag\n",
    "    qcf_original = prd[1].item()\n",
    "    # Probability that quote conversion flag is as predicted\n",
    "    prb_original = prd[2][qcf_original].item()\n",
    "    lst_df_for_field = []\n",
    "    # Loop through all fields. Check different values of each field to see if result is sensitive to it.\n",
    "    df_ind_original = ind_original.to_frame().T\n",
    "    for field in df.columns:\n",
    "        val_original = ind_original[field]\n",
    "        lst_val = lst_ind_value(df, field)\n",
    "        lst_df_for_field.append(df_for_field(df_ind_original, field, lst_val))\n",
    "    logger.info(f\"Build lst_df_for_field time = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    df_sensitivity = pd.concat(lst_df_for_field, ignore_index=True)\n",
    "#     logger.info(f\"{df_sensitivity['Field7'].unique()=}\")\n",
    "    logger.info(f\"Concat time = {(datetime.now() - time_start).total_seconds()} seconds {df_sensitivity.shape=}\")\n",
    "    sr_fieldname = df_sensitivity['fieldname']\n",
    "    df_sensitivity.drop('fieldname', inplace=True, axis=1)\n",
    "    dl = learn.dls.test_dl(df_sensitivity)\n",
    "    logger.info(f\"Dataloader time = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    dl.dataset.conts = dl.dataset.conts.astype(np.float32)\n",
    "    # stop learn.get_preds() printing blank lines\n",
    "    with io.capture_output() as captured:\n",
    "        # using get_preds() rather than predict() because get_preds can do multiple rows at once\n",
    "        inp,preds,_,dec_preds = learn.get_preds(dl=dl, with_input=True, with_decoded=True)\n",
    "    logger.info(f\"Time taken = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    df_results=pd.DataFrame({'fieldname': sr_fieldname, 'prob_success': preds[:,1]})\n",
    "    df_results.sort_values(by='prob_success', ascending=False, inplace=True)\n",
    "    return df_results, df_sensitivity\n",
    "\n",
    "def sensitivity_analysis_for_quote_number(qn):\n",
    "    return sensitivity_analysis(df.loc[qn])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a35f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widget event handlers\n",
    "def configure_inputs():\n",
    "    \"\"\"Dynamically create inputs (dropdowns and radio buttons) for trialling combinations of values to improve quote success\"\"\"\n",
    "    qn = wdg_quote_number_slider.value\n",
    "    # Get the top 10 fields most likely to make quote more successful, and their values which work the best\n",
    "    i = 0\n",
    "    dct_fields = defaultdict(list)\n",
    "    while len(dct_fields.keys()) < 10 and i < df.shape[1]:\n",
    "        f = df_results.iloc[i, 0]  # fieldname column\n",
    "        idx = df_results.index[i]  # index into df_sensitivity\n",
    "        # independent variable value which has a good result\n",
    "        ind_val = df_sensitivity.loc[idx, f]\n",
    "        # create a list of all values which have a good result for this field\n",
    "        dct_fields[f].append(ind_val)\n",
    "        i += 1\n",
    "    priority = 0\n",
    "    # delete all elements of lst_input and lst_hbox without deleting references\n",
    "    del lst_input[:]\n",
    "    del lst_vbox[:]\n",
    "    for f, lst_recommend in dct_fields.items():\n",
    "        priority += 1\n",
    "        num_unique = df[f].nunique()\n",
    "        lst_unique = df[f].unique()\n",
    "        try:\n",
    "            tf_nan = sum(np.isnan(lst_unique)) > 0\n",
    "        except TypeError:\n",
    "            tf_nan = False\n",
    "        if tf_nan:\n",
    "            lst_unique = df[f].dropna().unique()\n",
    "        lst_unique = sorted(lst_unique)\n",
    "        if tf_nan:\n",
    "            lst_unique.append(\"nan\")\n",
    "        v = nan_if_nan(df.loc[qn,f])\n",
    "        tip = f\"Priority {priority}. Initially {v}. Recommend {lst_recommend}\"\n",
    "        lbl = widgets.HTML(value=f\"{tip}\")\n",
    "        if num_unique < 5:\n",
    "            wdg = widgets.RadioButtons(options=lst_unique, \n",
    "                                       description=f, \n",
    "                                       description_tooltip=tip,\n",
    "                                       style=style_input, \n",
    "                                       value=v)\n",
    "        else:\n",
    "            wdg = widgets.Dropdown(options=lst_unique, \n",
    "                                   description=f, \n",
    "                                   description_tooltip=tip,\n",
    "                                   style=style_input, \n",
    "                                   value=v)\n",
    "        wdg.observe(handle_input_change, names='value')\n",
    "        lst_vbox.append(widgets.HBox(children=[wdg, lbl]))\n",
    "        lst_input.append(wdg)\n",
    "        wdg_inputs.children=lst_vbox\n",
    "        \n",
    "def do_progress_bar(progress):\n",
    "    total = 100\n",
    "    for i in range(total):\n",
    "        time.sleep(0.2)\n",
    "        progress.value = float(i + 1) / total\n",
    "\n",
    "def do_sensitivity_analysis(btn=None):\n",
    "    \"\"\"Do a fresh sensitivity analysis for selected quote number\"\"\"\n",
    "    global df_results, df_sensitivity\n",
    "    \n",
    "    thread = threading.Thread(target=do_progress_bar, args=(wdg_progress,))\n",
    "    wdg_progress.layout.visibility = 'visible'\n",
    "    thread.start()\n",
    "    qn = wdg_quote_number_slider.value\n",
    "    wdg_logging_out.clear_output()\n",
    "    with wdg_logging_out:\n",
    "        df_results, df_sensitivity = sensitivity_analysis_for_quote_number(qn)\n",
    "    wdg_prob_success_out.clear_output()\n",
    "    with wdg_prob_success_out:\n",
    "        print(df_results.head(20))\n",
    "    configure_inputs()\n",
    "    handle_input_change(0)\n",
    "    wdg_progress.layout.visibility = 'hidden'\n",
    "\n",
    "def handle_input_change(change):\n",
    "    qn = wdg_quote_number_slider.value\n",
    "    ind = df.loc[qn].copy()\n",
    "    for w in lst_input:\n",
    "        if w.value == \"nan\":\n",
    "            v = np.nan\n",
    "        else:\n",
    "            v = w.value\n",
    "        ind[w.description] = v\n",
    "    with io.capture_output() as captured:\n",
    "        prd = learn.predict(ind)\n",
    "    qcf = prd[1].item()\n",
    "    prb = prd[2][qcf].item()\n",
    "    act = dct_success_label[sr_conv[qn]] if qn in sr_conv else \"unknown\"\n",
    "    wdg_status.value = f\"<h2>Quote {qn} actual: {act}, predicted: {prb:.2%} {dct_success_label[qcf]}</h2>\"\n",
    "\n",
    "\n",
    "def handle_quote_number_change(change):\n",
    "    qn = change.new\n",
    "    with io.capture_output() as captured:\n",
    "        prd = learn.predict(df.loc[qn])\n",
    "    qcf = prd[1].item()\n",
    "    prb = prd[2][qcf].item()\n",
    "    act = dct_success_label[sr_conv[qn]] if qn in sr_conv else \"unknown\"\n",
    "    wdg_quote_success.value = f\"Quote {change.new} actual: {act}, predicted {prb:.2%} {dct_success_label[qcf]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c233a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_input = []\n",
    "lst_vbox = []\n",
    "# define all standard widgets\n",
    "wdg_quote_success = widgets.Label(value=\"\")\n",
    "dct_success_label = {0: \"unsuccessful\", 1: \"successful\"}\n",
    "style_qn = {'description_width': 'initial', 'width': '500px'}\n",
    "style_input = {'description_width': 'initial'}\n",
    "wdg_quote_number_text = widgets.BoundedIntText(\n",
    "    description=\"Quote number\", min=qn_min, max=qn_max, value=qn, style=style_qn)\n",
    "wdg_quote_number_slider = widgets.IntSlider(\n",
    "    description=\"Quote number\", min=qn_min, max=qn_max, value=qn, style=style_qn, layout={'width': '600px'})\n",
    "# link slider and textfield together\n",
    "qn_link = widgets.jslink((wdg_quote_number_text, 'value'), (wdg_quote_number_slider, 'value'))\n",
    "wdg_quote_number_slider.observe(handle_quote_number_change, names='value')\n",
    "wdg_sensitivity_analysis_button = widgets.Button(\n",
    "    description='Sensitivity Analysis',\n",
    "    tooltip='Do a fresh sensitivity analysis for selected quote number and display top 10 inputs ',\n",
    ")\n",
    "wdg_sensitivity_analysis_button.on_click(do_sensitivity_analysis)\n",
    "wdg_status = widgets.HTML(value=f\"<h2>Please click on button 'Sensitivity Analysis' and wait 20 seconds</h2>\")\n",
    "wdg_logging_out = widgets.Output(layout={'border': '1px solid green'})\n",
    "wdg_prob_success_out = widgets.Output()\n",
    "wdg_inputs = widgets.VBox(children=lst_vbox)\n",
    "wdg_progress = widgets.FloatProgress(value=0.0, min=0.0, max=1.0)\n",
    "wdg_progress.layout.visibility = 'hidden'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb35e5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a644830bcb4ac0bb84ab34c092bad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=197430, description='Quote number', max=434588, min=1, style=DescriptionStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9997a4e1748f4ffe94f8febd1ea30e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=197430, description='Quote number', layout=Layout(width='600px'), max=434588, min=1, style=Sli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a26b25d7c04c7f801bda7ce1a35298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13f516b4d2f445e884fe4743da9f583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Sensitivity Analysis', style=ButtonStyle(), tooltip='Do a fresh sensitivity analysis for s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addd8ce340fc49beb88790f02eae5408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(visibility='hidden'), max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c049f1f1253a405fb3b4156d32de3075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h2>Please click on button 'Sensitivity Analysis' and wait 20 seconds</h2>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2c0668e5ef47038ec7b7e2d3a1a3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0c12725b9d43b28cb4109620f5d9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wdg_quote_number_text)\n",
    "display(wdg_quote_number_slider)\n",
    "display(wdg_quote_success)\n",
    "display(wdg_sensitivity_analysis_button)\n",
    "display(wdg_progress)\n",
    "display(wdg_status)\n",
    "display(wdg_inputs)\n",
    "display(wdg_prob_success_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085582cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
