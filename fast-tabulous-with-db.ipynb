{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7e2183",
   "metadata": {},
   "source": [
    "# fast-tabulous homesite quote success app\n",
    "Select quote number from text box or slider and click on \"Sensitivity Analysis\" button.\n",
    "\n",
    "Fastai Deep Learning Part 1 2021. Source code available at https://github.com/timcu/fast-tabulous-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eca4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "\n",
    "from fastai.tabular.all import *\n",
    "from IPython.display import display\n",
    "from IPython.utils import io  # using io.capture_output\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdee60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now specify the folder which contains the original kaggle data (train.csv and test.csv) \n",
    "# and the trained TabularModel (learn_model_cpu_0708.pkl) and DataLoaders (dls_cpu_0708.pkl)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "path = Path('homesite-quote')\n",
    "logger = logging.getLogger(\"load_pickled_model\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f0b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavyweight = \"model_cpu_dls_cpu\", Lightweight = \"export_load_learner\"\n",
    "learner_source = \"export_load_learner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e7dbd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavyweight solution - disabled for now\n",
    "\n",
    "# On GPU instance run the following commands\n",
    "\n",
    "#     to = TabularPandas(df=df_train, procs=procs, cat_names=cat_names, cont_names=cont_names, y_names=y_names,splits=splits, y_block=y_block)dls = to.dataloaders(bs=bs, val_bs=val_bs, layers=layers, embed_ps=emb_dropout, ps=dropout)\n",
    "#     dls = to.dataloaders(bs=bs, val_bs=val_bs, layers=layers, embed_ps=emb_dropout, ps=dropout)\n",
    "#     learn = tabular_learner(dls, metrics=roc_auc_binary)\n",
    "    \n",
    "#     save_pickle(\"to_0708.pkl\", to)\n",
    "#     learn_model_cpu = learn.model.to('cpu')\n",
    "#     save_pickle(\"learn_model_cpu_0708.pkl\", learn_model_cpu)\n",
    "#     dls.to('cpu')\n",
    "#     save_pickle(\"dls_cpu_0708.pkl\", dls)\n",
    "\n",
    "if learner_source == \"model_cpu_dls_cpu\":\n",
    "    learn_model_cpu = load_pickle(path/\"learn_model_cpu_0708.pkl\")\n",
    "    dls_cpu = load_pickle(path/\"dls_cpu_0708.pkl\")\n",
    "    to = load_pickle(path/\"to_0708.pkl\")  # optional for now. needed for xgboost\n",
    "    learn=TabularLearner(dls=dls_cpu, model=learn_model_cpu)\n",
    "    preds, targs = learn.get_preds()\n",
    "    logger.warning(f\"Trained deep learning model has a roc_auc_score of {roc_auc_score(to_np(targs), to_np(preds[:,1]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbcee33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightweight solution - enabled for now\n",
    "\n",
    "# On GPU instance run the following command\n",
    "#     learn.export(fname=\"learn_empty_dls_0708.pkl\")\n",
    "if learner_source == \"export_load_learner\":\n",
    "    learn = load_learner(path/\"learn_empty_dls_0708.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "158737bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst_ind_value(df, field):\n",
    "    \"\"\"Return the list of independent values to be tested for specified field\"\"\"\n",
    "    num_unique = df[field].nunique()\n",
    "    # If number of unique values is under 30 then try every value (or for objects try every value)\n",
    "    if num_unique < 30 or df.dtypes[field] == 'O':\n",
    "        return df[field].dropna().unique().tolist()\n",
    "    else:\n",
    "        if df.dtypes[field] == \"int64\":\n",
    "            vmin = df[field].min()\n",
    "            vmax = df[field].max()\n",
    "            return [int(vmin + (vmax - vmin) * i // 10) for i in range(11)]\n",
    "        elif df.dtypes[field] == \"float64\":\n",
    "            vmin = df[field].min()\n",
    "            vmax = df[field].max()\n",
    "            return [float(vmin + (vmax - vmin) * i / 10) for i in range(11)]\n",
    "        else:\n",
    "            logger.warning(f\"Unknown type {field} {num_unique} {df.dtypes[field]!r}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962ed0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = mongo['db_homesite']\n",
    "clct_quote = db['clct_quote']\n",
    "clct_conv = db['clct_conv']\n",
    "clct_vals_by_col = db['clct_vals_by_col']\n",
    "# If database exists we don't have to create it again\n",
    "if clct_quote.count_documents({\"QuoteNumber\": 1}) == 0:\n",
    "    df_train = pd.read_csv(path/'train.csv', low_memory=False, parse_dates=['Original_Quote_Date'], index_col=\"QuoteNumber\")\n",
    "    df_test = pd.read_csv(path/'test.csv', low_memory=False, parse_dates=['Original_Quote_Date'], index_col=\"QuoteNumber\")\n",
    "    sr_conv = df_train['QuoteConversion_Flag']\n",
    "    df_train.drop('QuoteConversion_Flag', inplace=True, axis=1)\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    df = add_datepart(df, 'Original_Quote_Date')\n",
    "    logger.debug(f\"{df.shape} {df_train.shape} {df_test.shape} {sr_conv.shape}\")\n",
    "    df_train = None\n",
    "    df_test = None\n",
    "    # Save to database\n",
    "    clct_quote.drop()\n",
    "    clct_quote.insert_many(df.reset_index().to_dict(\"records\"))\n",
    "    clct_quote.create_index(\"QuoteNumber\", name=\"idx_qn\", unique=True)\n",
    "    clct_conv.drop()\n",
    "    clct_conv.insert_many(sr_conv.to_frame().reset_index().to_dict(\"records\"))\n",
    "    clct_conv.create_index(\"QuoteNumber\", name=\"idx_qn\", unique=True)\n",
    "    clct_vals_by_col.drop()\n",
    "    clct_vals_by_col.create_index(\"vc_column\", name=\"idx_vc_column\", unique=True)\n",
    "    for f in df.columns:\n",
    "        num_unique = df[f].nunique()\n",
    "        tf_nan = int(df[f].isnull().sum()) > 0\n",
    "        lst_value = sorted(list(lst_ind_value(df, f)))\n",
    "        clct_vals_by_col.insert_one({\"vc_column\": f, \"lst_value\": lst_value, \"num_unique\": num_unique, \"tf_nan\": tf_nan, \"dtype\": str(df[f].dtype)})\n",
    "\n",
    "cursor = clct_quote.aggregate([{\"$group\": {\"_id\": \"QuoteNumber\", \"first\": {\"$min\": \"$QuoteNumber\"}, \"last\": {\"$max\": \"$QuoteNumber\"}}}])\n",
    "quote_range = list(cursor)[0]\n",
    "qn_min = quote_range['first']\n",
    "qn_max = quote_range['last']\n",
    "qn = random.randint(qn_min, qn_max)  # pick an initial quote at random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76d997bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_equal_or_nan(a, b):\n",
    "    \"\"\"same as normal equals except np.nan == np.nan which is not normally True\"\"\"\n",
    "    if a == b:\n",
    "        return True\n",
    "    try:\n",
    "        if np.isnan(a) and np.isnan(b):\n",
    "            return True\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def nan_if_nan(n):\n",
    "    \"\"\"Can't include np.nan in dropdowns as np.nan != np.nan. Instead use a str\"\"\"\n",
    "    try:\n",
    "        if np.isnan(n):\n",
    "            return \"nan\"\n",
    "    except TypeError as te:\n",
    "        pass\n",
    "    return n\n",
    "        \n",
    "def df_for_field(df_ind_original, f, lst_v):\n",
    "    \"\"\"predicts quote success after changing field f from v_original to each value in lst_v.\n",
    "    If prediction changes then quote is sensitive to the value of this field and True is returned\n",
    "    Keyword arguments\n",
    "        df_ind_original: all independent values from original quote (Pandas DataFrame with index = quote number, column names = independent value field names) \n",
    "        f: field name\n",
    "        lst_v: list of alternative values of independent value in field f\n",
    "    Returns\n",
    "        dataframe of alternative values in field f and all other fields staying the same and a column called fieldname\n",
    "    \"\"\"\n",
    "    # Create a DataFrame which has every row identical except for field in question\n",
    "    # Field f iterates through every value provided\n",
    "    ind_other = df_ind_original.drop(f, axis=1)  # fields other than f\n",
    "    ind_f = pd.DataFrame(data={f: lst_v, \"fieldname\": [f] * len(lst_v)}, index=[df_ind_original.index[0]] * len(lst_v))\n",
    "    # Merge these two DataFrames to create one with all rows identical except field f\n",
    "    return pd.merge(ind_other, ind_f, right_index=True, left_index=True)\n",
    "\n",
    "def sensitivity_analysis(ind_original):\n",
    "    \"\"\"Using data from Series of independent variables do a sensitivity analysis on all independent variables\n",
    "    \n",
    "    ind_original is a Pandas Series of independent variables with their original values\"\"\"\n",
    "    time_start = datetime.now()\n",
    "    # Original prediction before changes\n",
    "    prd = learn.predict(ind_original)\n",
    "    logger.debug(f\"After one predict time = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    # Predicted quote conversion flag\n",
    "    qcf_original = prd[1].item()\n",
    "    # Probability that quote conversion flag is as predicted\n",
    "    prb_original = prd[2][qcf_original].item()\n",
    "    lst_df_for_field = []\n",
    "    # Loop through all fields. Check different values of each field to see if result is sensitive to it.\n",
    "    cursor = clct_vals_by_col.find({})\n",
    "    dct_types = {d['vc_column']: d['dtype'] for d in cursor}\n",
    "    df_ind_original = ind_original.to_frame().T.astype(dct_types)\n",
    "    for field in df_ind_original.columns:\n",
    "        val_original = ind_original[field]\n",
    "        dct_vals_by_col = clct_vals_by_col.find_one({\"vc_column\": field})\n",
    "        lst_val = dct_vals_by_col['lst_value']\n",
    "        if dct_vals_by_col['tf_nan']:\n",
    "            if len(lst_val) > 0 and isinstance(lst_val[0], str):\n",
    "                lst_val.append('nan')\n",
    "            else:\n",
    "                lst_val.append(np.nan)\n",
    "        lst_df_for_field.append(df_for_field(df_ind_original, field, lst_val))\n",
    "    logger.info(f\"Build lst_df_for_field time = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    df_sensitivity = pd.concat(lst_df_for_field, ignore_index=True)\n",
    "#     logger.info(f\"{df_sensitivity['Field7'].unique()=}\")\n",
    "    logger.info(f\"Concat time = {(datetime.now() - time_start).total_seconds()} seconds {df_sensitivity.shape=}\")\n",
    "    sr_fieldname = df_sensitivity['fieldname']\n",
    "    df_sensitivity.drop('fieldname', inplace=True, axis=1)\n",
    "    dl = learn.dls.test_dl(df_sensitivity)\n",
    "    logger.info(f\"Dataloader time = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    dl.dataset.conts = dl.dataset.conts.astype(np.float32)\n",
    "    # stop learn.get_preds() printing blank lines\n",
    "    with io.capture_output() as captured:\n",
    "        # using get_preds() rather than predict() because get_preds can do multiple rows at once\n",
    "        inp,preds,_,dec_preds = learn.get_preds(dl=dl, with_input=True, with_decoded=True)\n",
    "    logger.info(f\"Time taken = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    df_results=pd.DataFrame({'fieldname': sr_fieldname, 'prob_success': preds[:,1]})\n",
    "    df_results.sort_values(by='prob_success', ascending=False, inplace=True)\n",
    "    return df_results, df_sensitivity\n",
    "\n",
    "def quote_as_series(quote_number):\n",
    "    \"\"\"Find quote and return as a Series\"\"\"\n",
    "    # Find quote and exclude fields _id and QuoteNumber\n",
    "    dct_quote = clct_quote.find_one({\"QuoteNumber\": quote_number}, projection={\"_id\": False, \"QuoteNumber\": False})\n",
    "    return pd.Series(dct_quote, name=quote_number)\n",
    "\n",
    "def sensitivity_analysis_for_quote_number(quote_number):\n",
    "    return sensitivity_analysis(quote_as_series(quote_number))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a35f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widget event handlers\n",
    "def configure_inputs():\n",
    "    \"\"\"Dynamically create inputs (dropdowns and radio buttons) for trialling combinations of values to improve quote success\"\"\"\n",
    "    qn = wdg_quote_number_slider.value\n",
    "    sr_quote = quote_as_series(qn)\n",
    "    # Get the top 10 fields most likely to make quote more successful, and their values which work the best\n",
    "    i = 0\n",
    "    dct_fields = defaultdict(list)\n",
    "    while len(dct_fields.keys()) < 10:\n",
    "        f = df_results.iloc[i, 0]  # fieldname column\n",
    "        idx = df_results.index[i]  # index into df_sensitivity\n",
    "        # independent variable value which has a good result\n",
    "        ind_val = df_sensitivity.loc[idx, f]\n",
    "        # create a list of all values which have a good result for this field\n",
    "        dct_fields[f].append(ind_val)\n",
    "        i += 1\n",
    "    priority = 0\n",
    "    # delete all elements of lst_input and lst_hbox without deleting references\n",
    "    del lst_input[:]\n",
    "    del lst_vbox[:]\n",
    "    for f, lst_recommend in dct_fields.items():\n",
    "        priority += 1\n",
    "        dct_vals_by_col = clct_vals_by_col.find_one({\"vc_column\": f})\n",
    "        num_unique = dct_vals_by_col['num_unique']  # df[f].nunique()\n",
    "        lst_unique = dct_vals_by_col['lst_value']  # df[f].unique()\n",
    "        if dct_vals_by_col['tf_nan']:\n",
    "            lst_unique.append('nan')\n",
    "        v = nan_if_nan(sr_quote[f])\n",
    "        if v not in lst_unique:\n",
    "            lst_unique.append(v)\n",
    "        tip = f\"Priority {priority}. Initially {v}. Recommend {lst_recommend}\"\n",
    "        lbl = widgets.HTML(value=f\"{tip}\")\n",
    "        if num_unique < 5:\n",
    "            wdg = widgets.RadioButtons(options=lst_unique, \n",
    "                                       description=f, \n",
    "                                       description_tooltip=tip, \n",
    "                                       style=style_input, \n",
    "                                       value=v)\n",
    "        else:\n",
    "            wdg = widgets.Dropdown(options=lst_unique, \n",
    "                                   description=f, \n",
    "                                   description_tooltip=tip,\n",
    "                                   style=style_input, \n",
    "                                   value=v)\n",
    "        wdg.observe(handle_input_change, names='value')\n",
    "        lst_vbox.append(widgets.HBox(children=[wdg, lbl]))\n",
    "        lst_input.append(wdg)\n",
    "        wdg_inputs.children=lst_vbox\n",
    "        \n",
    "def do_progress_bar(progress):\n",
    "    total = 100\n",
    "    for i in range(total):\n",
    "        time.sleep(0.2)\n",
    "        progress.value = float(i + 1) / total\n",
    "\n",
    "def do_sensitivity_analysis(btn=None):\n",
    "    \"\"\"Do a fresh sensitivity analysis for selected quote number\"\"\"\n",
    "    global df_results, df_sensitivity\n",
    "    \n",
    "    thread = threading.Thread(target=do_progress_bar, args=(wdg_progress,))\n",
    "    wdg_progress.layout.visibility = 'visible'\n",
    "    thread.start()\n",
    "    qn = wdg_quote_number_slider.value\n",
    "    wdg_logging_out.clear_output()\n",
    "    with wdg_logging_out:\n",
    "        df_results, df_sensitivity = sensitivity_analysis_for_quote_number(qn)\n",
    "    wdg_prob_success_out.clear_output()\n",
    "    with wdg_prob_success_out:\n",
    "        print(df_results.head(20))\n",
    "    configure_inputs()\n",
    "    handle_input_change(0)\n",
    "    wdg_progress.layout.visibility = 'hidden'\n",
    "\n",
    "def handle_input_change(change):\n",
    "    qn = wdg_quote_number_slider.value\n",
    "    ind = quote_as_series(qn)\n",
    "    for w in lst_input:\n",
    "        if w.value == \"nan\":\n",
    "            v = np.nan\n",
    "        else:\n",
    "            v = w.value\n",
    "        ind[w.description] = v\n",
    "    with io.capture_output() as captured:\n",
    "        prd = learn.predict(ind)\n",
    "    qcf = prd[1].item()\n",
    "    prb = prd[2][qcf].item()\n",
    "    lst_conv = list(clct_conv.find({\"QuoteNumber\": qn}))\n",
    "    act = dct_success_label[lst_conv[0][\"QuoteConversion_Flag\"]] if len(lst_conv) > 0 else \"unknown\"\n",
    "    wdg_status.value = f\"<h2>Quote {qn} actual: {act}, predicted: {prb:.2%} {dct_success_label[qcf]}</h2>\"\n",
    "\n",
    "\n",
    "def calc_quote_success(quote_number):\n",
    "    \"\"\"Calculate success of quote number  and show result\"\"\"\n",
    "    with io.capture_output() as captured:\n",
    "        prd = learn.predict(quote_as_series(quote_number))\n",
    "    qcf = prd[1].item()\n",
    "    prb = prd[2][qcf].item()\n",
    "    lst_conv = list(clct_conv.find({\"QuoteNumber\": quote_number}))\n",
    "    act = dct_success_label[lst_conv[0][\"QuoteConversion_Flag\"]] if len(lst_conv) > 0 else \"unknown\"\n",
    "    wdg_quote_success.value = f\"Quote {quote_number} actual: {act}, predicted {prb:.2%} {dct_success_label[qcf]}\"\n",
    "\n",
    "def handle_quote_number_change(change):\n",
    "    calc_quote_success(change.new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c233a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_input = []\n",
    "lst_vbox = []\n",
    "# define all standard widgets\n",
    "wdg_quote_success = widgets.Label(value=\"\")\n",
    "dct_success_label = {0: \"unsuccessful\", 1: \"successful\"}\n",
    "style_qn = {'description_width': 'initial', 'width': '500px'}\n",
    "style_input = {'description_width': 'initial'}\n",
    "wdg_quote_number_text = widgets.BoundedIntText(\n",
    "    description=\"Quote number\", min=qn_min, max=qn_max, value=qn, style=style_qn)\n",
    "wdg_quote_number_slider = widgets.IntSlider(\n",
    "    description=\"Quote number\", min=qn_min, max=qn_max, value=qn, style=style_qn, layout={'width': '600px'})\n",
    "# link slider and textfield together\n",
    "qn_link = widgets.jslink((wdg_quote_number_text, 'value'), (wdg_quote_number_slider, 'value'))\n",
    "wdg_quote_number_slider.observe(handle_quote_number_change, names='value')\n",
    "wdg_sensitivity_analysis_button = widgets.Button(\n",
    "    description='Sensitivity Analysis',\n",
    "    tooltip='Do a fresh sensitivity analysis for selected quote number and display top 10 inputs ',\n",
    ")\n",
    "wdg_sensitivity_analysis_button.on_click(do_sensitivity_analysis)\n",
    "wdg_status = widgets.HTML(value=f\"<h2>Please click on button 'Sensitivity Analysis' and wait 20 seconds</h2>\")\n",
    "wdg_logging_out = widgets.Output(layout={'border': '1px solid green'})\n",
    "wdg_prob_success_out = widgets.Output()\n",
    "wdg_inputs = widgets.VBox(children=lst_vbox)\n",
    "wdg_progress = widgets.FloatProgress(value=0.0, min=0.0, max=1.0)\n",
    "wdg_progress.layout.visibility = 'hidden'\n",
    "calc_quote_success(qn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb35e5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51478c915d1d4a6db3912e215e727d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=257954, description='Quote number', max=434589, min=1, style=DescriptionStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bfbbea5cba4c80a65ed5731d8c6fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=257954, description='Quote number', layout=Layout(width='600px'), max=434589, min=1, style=Sli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abeb62abcc1436b8218ead0d394b645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Quote 257954 actual: unknown, predicted 96.47% unsuccessful')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c008ac3a9e54493f903fd80fd6890efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Sensitivity Analysis', style=ButtonStyle(), tooltip='Do a fresh sensitivity analysis for s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d03afa4cd74f0bb0e9f438cf17f482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(visibility='hidden'), max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfad1d9c27c413d81d4ce04bf0d6a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h2>Please click on button 'Sensitivity Analysis' and wait 20 seconds</h2>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465a4687625a4d92bd43a5e3ba002d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e0d319c69b437399e0007872f0a059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v not in unique v=1 dct_vals_by_col={'_id': ObjectId('60ffcef86434478cdd25160a'), 'vc_column': 'PersonalField14', 'lst_value': [0, 6, 13, 19, 26, 32, 39, 45, 52, 58, 65], 'num_unique': 37, 'tf_nan': False, 'dtype': 'int64'}\n"
     ]
    }
   ],
   "source": [
    "display(wdg_quote_number_text)\n",
    "display(wdg_quote_number_slider)\n",
    "display(wdg_quote_success)\n",
    "display(wdg_sensitivity_analysis_button)\n",
    "display(wdg_progress)\n",
    "display(wdg_status)\n",
    "display(wdg_inputs)\n",
    "display(wdg_prob_success_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085582cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
