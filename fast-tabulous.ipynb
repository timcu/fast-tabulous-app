{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7e2183",
   "metadata": {},
   "source": [
    "# fast-tabulous homesite quote success app\n",
    "> Select quote number from text box or slider and click on \"Sensitivity analysis\" button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eca4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fastai.tabular.all import *\n",
    "from IPython.display import display\n",
    "from IPython.utils import io  # using io.capture_output\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdee60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now specify the folder which contains the original kaggle data (train.csv and test.csv) \n",
    "# and the trained TabularModel (learn_model_cpu_0708.pkl) and DataLoaders (dls_cpu_0708.pkl)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "path = Path('homesite-quote')\n",
    "logger = logging.getLogger(\"load_pickled_model\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavyweight = \"model_cpu_dls_cpu\", Lightweight = \"export_load_learner\"\n",
    "learner_source = \"export_load_learner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7dbd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavyweight solution - disabled for now\n",
    "\n",
    "# On GPU instance run the following commands\n",
    "\n",
    "#     to = TabularPandas(df=df_train, procs=procs, cat_names=cat_names, cont_names=cont_names, y_names=y_names,splits=splits, y_block=y_block)dls = to.dataloaders(bs=bs, val_bs=val_bs, layers=layers, embed_ps=emb_dropout, ps=dropout)\n",
    "#     dls = to.dataloaders(bs=bs, val_bs=val_bs, layers=layers, embed_ps=emb_dropout, ps=dropout)\n",
    "#     learn = tabular_learner(dls, metrics=roc_auc_binary)\n",
    "    \n",
    "#     save_pickle(\"to_0708.pkl\", to)\n",
    "#     learn_model_cpu = learn.model.to('cpu')\n",
    "#     save_pickle(\"learn_model_cpu_0708.pkl\", learn_model_cpu)\n",
    "#     dls.to('cpu')\n",
    "#     save_pickle(\"dls_cpu_0708.pkl\", dls)\n",
    "\n",
    "if learner_source == \"model_cpu_dls_cpu\":\n",
    "    learn_model_cpu = load_pickle(path/\"learn_model_cpu_0708.pkl\")\n",
    "    dls_cpu = load_pickle(path/\"dls_cpu_0708.pkl\")\n",
    "    to = load_pickle(path/\"to_0708.pkl\")  # optional for now. needed for xgboost\n",
    "    learn=TabularLearner(dls=dls_cpu, model=learn_model_cpu)\n",
    "    preds, targs = learn.get_preds()\n",
    "    logger.warning(f\"Trained deep learning model has a roc_auc_score of {roc_auc_score(to_np(targs), to_np(preds[:,1]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcee33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightweight solution - disabled for now\n",
    "\n",
    "# On GPU instance run the following commands\n",
    "if learner_source == \"export_load_learner\":\n",
    "    learn = load_learner(path/\"learn_empty_dls_0708.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "962ed0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path/'train.csv', low_memory=False, parse_dates=['Original_Quote_Date'], index_col=\"QuoteNumber\")\n",
    "df_test = pd.read_csv(path/'test.csv', low_memory=False, parse_dates=['Original_Quote_Date'], index_col=\"QuoteNumber\")\n",
    "sr_conv = df_train['QuoteConversion_Flag']\n",
    "df_train.drop('QuoteConversion_Flag', inplace=True, axis=1)\n",
    "df = pd.concat([df_train, df_test])\n",
    "df = add_datepart(df, 'Original_Quote_Date')\n",
    "logger.debug(f\"{df.shape} {df_train.shape} {df_test.shape} {sr_conv.shape}\")\n",
    "df_train = None\n",
    "df_test = None\n",
    "qn_min = sr_conv.index.min()\n",
    "qn_max = sr_conv.index.max()\n",
    "qn = random.randint(qn_min, qn_max)  # pick an initial quote at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d997bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst_ind_value(df, field):\n",
    "    \"\"\"Return the list of independent values to be tested for specified field\"\"\"\n",
    "    num_unique = df[field].nunique()\n",
    "    # If number of unique values is under 30 then try every value (or for objects try every value)\n",
    "    if num_unique < 30 or df.dtypes[field] == 'O':\n",
    "        return df[field].unique()\n",
    "    else:\n",
    "        if df.dtypes[field] == \"int64\":\n",
    "            vmin = df[field].min()\n",
    "            vmax = df[field].max()\n",
    "            return [vmin + (vmax - vmin) * i // 10 for i in range(11)]\n",
    "        elif df.dtypes[field] == \"float64\":\n",
    "            vmin = df[field].min()\n",
    "            vmax = df[field].max()\n",
    "            return [vmin + (vmax - vmin) * i / 10 for i in range(11)]\n",
    "        else:\n",
    "            logger.warning(f\"Unknown type {field} {num_unique} {df.dtypes[field]!r}\")\n",
    "            return []\n",
    "\n",
    "def tf_equal_or_nan(a, b):\n",
    "    \"\"\"same as normal equals except np.nan == np.nan which is not normally True\"\"\"\n",
    "    if a == b:\n",
    "        return True\n",
    "    try:\n",
    "        if np.isnan(a) and np.isnan(b):\n",
    "            return True\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def nan_if_nan(n):\n",
    "    \"\"\"Can't include np.nan in dropdowns as np.nan != np.nan. Instead use a str\"\"\"\n",
    "    try:\n",
    "        if np.isnan(n):\n",
    "            return \"nan\"\n",
    "    except TypeError as te:\n",
    "        pass\n",
    "    return n\n",
    "        \n",
    "def df_for_field(df_ind_original, f, lst_v):\n",
    "    \"\"\"predicts quote success after changing field f from v_original to each value in lst_v.\n",
    "    If prediction changes then quote is sensitive to the value of this field and True is returned\n",
    "    Keyword arguments\n",
    "        ind_original: all independent values from original quote (numpy Series with index = field names) \n",
    "        f: field name\n",
    "        lst_v: list of alternative values of independent value in field f\n",
    "    Returns\n",
    "        dataframe of alternative values in field f and all other fields staying the same and a column called fieldname\n",
    "    \"\"\"\n",
    "    # Create a DataFrame which has every row identical except for field in question\n",
    "    # Field f iterates through every value provided\n",
    "    ind_other = df_ind_original.drop(f, axis=1)  # fields other than f\n",
    "#     ind_other = df_ind_original.copy()  # fields other than f\n",
    "    ind_f = pd.DataFrame(data={f: lst_v, \"fieldname\": [f] * len(lst_v)}, index=[df_ind_original.index[0]] * len(lst_v))\n",
    "    # Merge these two DataFrames to create one with all rows identical except field f\n",
    "    return pd.merge(ind_other, ind_f, right_index=True, left_index=True)\n",
    "\n",
    "def sensitivity_analysis(ind_original):\n",
    "    \"\"\"Using data from Series of independent variables do a sensitivity analysis on all independent variables\"\"\"\n",
    "    time_start = datetime.now()\n",
    "    # Original prediction before changes\n",
    "    prd = learn.predict(ind_original)\n",
    "    logger.debug(f\"After one predict time = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    # Predicted quote conversion flag\n",
    "    qcf_original = prd[1].item()\n",
    "    # Probability that quote conversion flag is as predicted\n",
    "    prb_original = prd[2][qcf_original].item()\n",
    "    lst_df_for_field = []\n",
    "    # Loop through all fields. Check different values of each field to see if result is sensitive to it.\n",
    "    df_ind_original = ind_original.to_frame().T\n",
    "    for field in df.columns:\n",
    "        val_original = ind_original[field]\n",
    "        lst_val = lst_ind_value(df, field)\n",
    "        lst_df_for_field.append(df_for_field(df_ind_original, field, lst_val))\n",
    "    logger.info(f\"Build lst_df_for_field time = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    df_sensitivity = pd.concat(lst_df_for_field, ignore_index=True)\n",
    "#     logger.info(f\"{df_sensitivity['Field7'].unique()=}\")\n",
    "    logger.info(f\"Concat time = {(datetime.now() - time_start).total_seconds()} seconds {df_sensitivity.shape=}\")\n",
    "    sr_fieldname = df_sensitivity['fieldname']\n",
    "    df_sensitivity.drop('fieldname', inplace=True, axis=1)\n",
    "    dl = learn.dls.test_dl(df_sensitivity)\n",
    "    logger.info(f\"Dataloader time = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    dl.dataset.conts = dl.dataset.conts.astype(np.float32)\n",
    "    # stop learn.get_preds() printing blank lines\n",
    "    with io.capture_output() as captured:\n",
    "        # using get_preds() rather than predict() because get_preds can do multiple rows at once\n",
    "        inp,preds,_,dec_preds = learn.get_preds(dl=dl, with_input=True, with_decoded=True)\n",
    "    logger.info(f\"Time taken = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    df_results=pd.DataFrame({'fieldname': sr_fieldname, 'prob_success': preds[:,1]})\n",
    "    df_results.sort_values(by='prob_success', ascending=False, inplace=True)\n",
    "    return df_results, df_sensitivity\n",
    "\n",
    "def sensitivity_analysis_for_quote_number(quote_number):\n",
    "    return sensitivity_analysis(df.loc[quote_number])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a35f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widget event handlers\n",
    "def configure_inputs():\n",
    "    \"\"\"Dynamically create inputs (dropdowns and radio buttons) for trialling combinations of values to improve quote success\"\"\"\n",
    "    qn = wdg_quote_number_slider.value\n",
    "    # Get the top 10 fields most likely to make quote more successful, and their values which work the best\n",
    "    i = 0\n",
    "    dct_fields = defaultdict(list)\n",
    "    while len(dct_fields.keys()) < 10 and i < df.shape[1]:\n",
    "        f = df_results.iloc[i, 0]  # fieldname column\n",
    "        idx = df_results.index[i]  # index into df_sensitivity\n",
    "        # independent variable value which has a good result\n",
    "        ind_val = df_sensitivity.loc[idx, f]\n",
    "        # create a list of all values which have a good result for this field\n",
    "        dct_fields[f].append(ind_val)\n",
    "        i += 1\n",
    "    priority = 0\n",
    "    # delete all elements of lst_input and lst_hbox without deleting references\n",
    "    del lst_input[:]\n",
    "    del lst_vbox[:]\n",
    "    for f, lst_recommend in dct_fields.items():\n",
    "        priority += 1\n",
    "        num_unique = df[f].nunique()\n",
    "        lst_unique = df[f].unique()\n",
    "        try:\n",
    "            tf_nan = sum(np.isnan(lst_unique)) > 0\n",
    "        except TypeError:\n",
    "            tf_nan = False\n",
    "        if tf_nan:\n",
    "            lst_unique = df[f].dropna().unique()\n",
    "        lst_unique = sorted(lst_unique)\n",
    "        if tf_nan:\n",
    "            lst_unique.append(\"nan\")\n",
    "        v = nan_if_nan(df.loc[qn,f])\n",
    "        tip = f\"Priority {priority}. Initially {v}. Recommend {lst_recommend}\"\n",
    "        lbl = widgets.HTML(value=f\"{tip}\")\n",
    "        if num_unique < 5:\n",
    "            wdg = widgets.RadioButtons(options=lst_unique, \n",
    "                                       description=f, \n",
    "                                       description_tooltip=tip,\n",
    "                                       style=style_input, \n",
    "                                       value=v)\n",
    "        else:\n",
    "            wdg = widgets.Dropdown(options=lst_unique, \n",
    "                                   description=f, \n",
    "                                   description_tooltip=tip,\n",
    "                                   style=style_input, \n",
    "                                   value=v)\n",
    "        wdg.observe(handle_input_change, names='value')\n",
    "        lst_vbox.append(widgets.HBox(children=[wdg, lbl]))\n",
    "        lst_input.append(wdg)\n",
    "        wdg_inputs.children=lst_vbox\n",
    "        \n",
    "def do_progress_bar(progress):\n",
    "    total = 100\n",
    "    for i in range(total):\n",
    "        time.sleep(0.2)\n",
    "        progress.value = float(i + 1) / total\n",
    "\n",
    "def do_sensitivity_analysis(btn=None):\n",
    "    \"\"\"Do a fresh sensitivity analysis for selected quote number\"\"\"\n",
    "    global df_results, df_sensitivity\n",
    "    \n",
    "    thread = threading.Thread(target=do_progress_bar, args=(wdg_progress,))\n",
    "    wdg_progress.layout.visibility = 'visible'\n",
    "    thread.start()\n",
    "    qn = wdg_quote_number_slider.value\n",
    "    wdg_logging_out.clear_output()\n",
    "    with wdg_logging_out:\n",
    "        df_results, df_sensitivity = sensitivity_analysis_for_quote_number(qn)\n",
    "    wdg_prob_success_out.clear_output()\n",
    "    with wdg_prob_success_out:\n",
    "        print(df_results.head(20))\n",
    "    configure_inputs()\n",
    "    handle_input_change(0)\n",
    "    wdg_progress.layout.visibility = 'hidden'\n",
    "\n",
    "def handle_input_change(change):\n",
    "    qn = wdg_quote_number_slider.value\n",
    "    ind = df.loc[qn].copy()\n",
    "    for w in lst_input:\n",
    "        if w.value == \"nan\":\n",
    "            v = np.nan\n",
    "        else:\n",
    "            v = w.value\n",
    "        ind[w.description] = v\n",
    "    with io.capture_output() as captured:\n",
    "        prd = learn.predict(ind)\n",
    "    qcf = prd[1].item()\n",
    "    prb = prd[2][qcf].item()\n",
    "    act = dct_success_label[sr_conv[qn]] if qn in sr_conv else \"unknown\"\n",
    "    wdg_status.value = f\"<h2>Quote {qn} actual: {act}, predicted: {prb:.2%} {dct_success_label[qcf]}</h2>\"\n",
    "\n",
    "\n",
    "def calc_quote_success(quote_number):\n",
    "    \"\"\"Calculate success of quote number  and show result\"\"\"\n",
    "    with io.capture_output() as captured:\n",
    "        prd = learn.predict(df.loc[quote_number])\n",
    "    qcf = prd[1].item()\n",
    "    prb = prd[2][qcf].item()\n",
    "    act = dct_success_label[sr_conv[quote_number]] if quote_number in sr_conv else \"unknown\"\n",
    "    wdg_quote_success.value = f\"Quote {quote_number} actual: {act}, predicted {prb:.2%} {dct_success_label[qcf]}\"\n",
    "\n",
    "def handle_quote_number_change(change):\n",
    "    calc_quote_success(change.new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c233a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_input = []\n",
    "lst_vbox = []\n",
    "# define all standard widgets\n",
    "wdg_quote_success = widgets.Label(value=\"\")\n",
    "dct_success_label = {0: \"unsuccessful\", 1: \"successful\"}\n",
    "style_qn = {'description_width': 'initial', 'width': '500px'}\n",
    "style_input = {'description_width': 'initial'}\n",
    "wdg_quote_number_text = widgets.BoundedIntText(\n",
    "    description=\"Quote number\", min=qn_min, max=qn_max, value=qn, style=style_qn)\n",
    "wdg_quote_number_slider = widgets.IntSlider(\n",
    "    description=\"Quote number\", min=qn_min, max=qn_max, value=qn, style=style_qn, layout={'width': '600px'})\n",
    "# link slider and textfield together\n",
    "qn_link = widgets.jslink((wdg_quote_number_text, 'value'), (wdg_quote_number_slider, 'value'))\n",
    "wdg_quote_number_slider.observe(handle_quote_number_change, names='value')\n",
    "wdg_sensitivity_analysis_button = widgets.Button(\n",
    "    description='Sensitivity Analysis',\n",
    "    tooltip='Do a fresh sensitivity analysis for selected quote number and display top 10 inputs ',\n",
    ")\n",
    "wdg_sensitivity_analysis_button.on_click(do_sensitivity_analysis)\n",
    "wdg_status = widgets.HTML(value=f\"<h2>Please click on button 'Sensitivity Analysis' and wait 20 seconds</h2>\")\n",
    "wdg_logging_out = widgets.Output(layout={'border': '1px solid green'})\n",
    "wdg_prob_success_out = widgets.Output()\n",
    "wdg_inputs = widgets.VBox(children=lst_vbox)\n",
    "wdg_progress = widgets.FloatProgress(value=0.0, min=0.0, max=1.0)\n",
    "wdg_progress.layout.visibility = 'hidden'\n",
    "calc_quote_success(qn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb35e5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489b12e5d41842d6b4acdecc417cea0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=401975, description='Quote number', max=434588, min=1, style=DescriptionStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f5128b37284e0bb8c8e037458eba1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=401975, description='Quote number', layout=Layout(width='600px'), max=434588, min=1, style=Sli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42763fbcdfdd4fd6a962a586850c1d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Quote 401975 actual: unknown, predicted 88.43% successful')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2607081ace2445f2a80eca68ca82f2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Sensitivity Analysis', style=ButtonStyle(), tooltip='Do a fresh sensitivity analysis for s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc1fc718c8b4c24923731f25606c3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(visibility='hidden'), max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41548ed9c374872a3fa04c1a472714e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h2>Please click on button 'Sensitivity Analysis' and wait 20 seconds</h2>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78392c2d74b4de881351f852182c745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ac1d3b0a084281ae2829ab7b046def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wdg_quote_number_text)\n",
    "display(wdg_quote_number_slider)\n",
    "display(wdg_quote_success)\n",
    "display(wdg_sensitivity_analysis_button)\n",
    "display(wdg_progress)\n",
    "display(wdg_status)\n",
    "display(wdg_inputs)\n",
    "display(wdg_prob_success_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085582cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
